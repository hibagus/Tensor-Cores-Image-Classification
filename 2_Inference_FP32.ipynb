{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE382V - Hardware Architecture for Machine Learning\n",
    "## NVIDIA Tensor Cores for Accelerating Machine Learning Workload\n",
    "\n",
    "## Notebook 2 - Inference using Trained Model with FP32\n",
    "\n",
    "In this notebook, we will try to make prediction using our trained model to see whether our model can classify cats and dogs from the image. We will use the test dataset to perform inference. Inference is not as heavy as training in terms of computational resources. Hardware designed for inference usually consider for low-power since most of the inference workloads are run on the edge device (e.g., smartphone)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library\n",
    "We need to import some libraries which are needed to perform some functions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variable\n",
    "Here, we define global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir       = './'\n",
    "raw_dir        = f'{data_dir}/raw'\n",
    "raw_dogs_dir   = f'{raw_dir}/dogs'\n",
    "raw_cats_dir   = f'{raw_dir}/cats'\n",
    "train_dir      = f'{data_dir}/train'\n",
    "train_dogs_dir = f'{train_dir}/dogs'\n",
    "train_cats_dir = f'{train_dir}/cats'\n",
    "val_dir        = f'{data_dir}/val'\n",
    "val_dogs_dir   = f'{val_dir}/dogs'\n",
    "val_cats_dir   = f'{val_dir}/cats'\n",
    "log_dir        = f'{data_dir}/log'\n",
    "chk_dir        = f'{data_dir}/checkpoint'\n",
    "test_dir       = f'{data_dir}/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Initialization\n",
    "We will use GPU to make prediction using our model. The TACC Maverick2 V100 Compute Node is equipped with two NVIDIA Tesla V100 GPUs. In this assignment, we will only use one of them. If there is no GPU available, we will revert back to use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Normalization\n",
    "Before we feed the input data (test images) into our model to get the prediction, we need to preprocess the images. The preprocessing step includes normalization and resizing to 224px by 224px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_test_transforms(inp):\n",
    "    out = transforms.functional.resize(inp, [224,224])\n",
    "    out = transforms.functional.to_tensor(out)\n",
    "    out = transforms.functional.normalize(out, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Handler\n",
    "We need a handler to open our input data (test images) and apply the transformation before feeding them into our model to get the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_from_fname(fname):\n",
    "    im = Image.open(f'{test_dir}/{fname}')\n",
    "    return apply_test_transforms(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Model\n",
    "We load the trained model using the checkpoint that we have saved after we have finished trained our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pre-trained model of ResNet-50\n",
    "model_conv  = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# We change the parameter of the final fully connected layer.\n",
    "# We have to keep the number of input features to this layer.\n",
    "# We change the output features from this layer into 2 features (i.e., we only have two classes).\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Define the checkpoint location to save the trained model\n",
    "check_point = f'{chk_dir}/model-checkpoint-fp32.tar'\n",
    "\n",
    "# Load the check_point\n",
    "checkpoint = torch.load(check_point)\n",
    "print(\"Checkpoint Loaded\")\n",
    "print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "model_conv.load_state_dict(checkpoint['model_state_dict'])\n",
    " \n",
    "# Copy the model to GPU memory\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "# Set the model to eval mode\n",
    "model_conv.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Prediction Function\n",
    "We will create a method to return the probability whether an image depicts a dog or not. If the probability is more than 50%, then the model predicts that it is an image of dog. If the probability is less than 50%, we can say that the model predicts that it is not an image of dog, instead it is an image of cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dog_prob_of_single_instance(model, tensor):\n",
    "    batch = torch.stack([tensor])\n",
    "    batch = batch.to(device) # Send the input to GPU\n",
    "    softMax = nn.Softmax(dim = 1)\n",
    "    preds = softMax(model(batch))\n",
    "    return preds[0,1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Let's make prediction on some images in test dataset. You can change the number of test images that you want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Change as needed ######################\n",
    "num_of_test_images = 32\n",
    "##############################################################\n",
    "\n",
    "test_data_files = os.listdir(test_dir)\n",
    "\n",
    "if(num_of_test_images<2) :\n",
    "    num_of_test_images = 2\n",
    "    \n",
    "image_inferenced   = 0\n",
    "fig, ax = plt.subplots(num_of_test_images, figsize=(num_of_test_images*5, num_of_test_images*5))\n",
    "fig.tight_layout(pad=5)\n",
    "\n",
    "for fname in test_data_files :    \n",
    "    im         = Image.open(f'{test_dir}/{fname}')\n",
    "    imstar     = apply_test_transforms(im)    \n",
    "    outputs    = predict_dog_prob_of_single_instance(model_conv, imstar)\n",
    "    ax[image_inferenced].imshow(im)\n",
    "    ax[image_inferenced].axis('on')\n",
    "    if(outputs<0.5) :\n",
    "        ax[image_inferenced].set_title('predicted: cat \\n probability: ' + str(1-outputs))\n",
    "    else :\n",
    "        ax[image_inferenced].set_title('predicted: dog \\n probability: ' + str(outputs))\n",
    "    image_inferenced += 1\n",
    "    if(image_inferenced>=num_of_test_images) :\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End\n",
    "This is the end of Notebook 2. Please move forward to Notebook 3 where we will use FP16 to train our model.\n",
    "\n",
    "!!IMPORTANT!! To close this Notebook, you have to use File -> Close and Halt. With this way, the Python process associated with this Notebook will also be killed.\n",
    "\n",
    "Version 0.9  - January 7th, 2020 - Â©2020 hanindhito@bagus.my.id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
